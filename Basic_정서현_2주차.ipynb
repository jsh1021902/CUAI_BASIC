{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPd0QirMFKBFaprIxFEkGcD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsh1021902/CUAI_BASIC/blob/main/Basic_%EC%A0%95%EC%84%9C%ED%98%84_2%EC%A3%BC%EC%B0%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 사이킷런 소개와 특징"
      ],
      "metadata": {
        "id": "7OTF_hb4RCNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **사이킷런** : 파이썬 기반의 머신러닝을 가장 쉽고 효율적인 개발 라이브러리 제공  "
      ],
      "metadata": {
        "id": "JTYYN69SbBxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **< 특징 >**\n",
        "1. 파이썬 기반의 다른 머신러닝 패키지도 사이킷런 스타일의 API를 지향할 정도로 **쉽고 가장 파이썬스러운 API**를 제공\n",
        "2. 머신러닝을 위한 매우 다양한 알고리즘과 개발을 위한 **편리한 프레임워크와 API**를 제공\n",
        "3. **오랜 기간 실전 환경에서 검증**됐으며, 매우 많은 환경에서 사용되는 성숙한 라이브러리"
      ],
      "metadata": {
        "id": "zkHzBno1bjs7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0eKLruUQXt9"
      },
      "outputs": [],
      "source": [
        "pip install -U scikit-learn          # 사이킷런 최신 버전을 설치하려면, 아나콘다 Prompt를 열고 다음과 같이 pip를 이용해 설치하면 됨."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "\n",
        "print(sklearn.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogoSyo85a2Tp",
        "outputId": "a4e67db2-7f79-419b-b8b9-de324a451f1d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 첫 번째 머신러닝 만들어 보기 - 붓꽃 품종 예측하기"
      ],
      "metadata": {
        "id": "tZ53USXQRJ2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 붓꽃 데이터 세트로 붓꽃의 품종을 **분류(Classification)**\n",
        "- **붓꽃 데이터 세트** : 꽃잎의 길이와 너비, 꽃받침의 길이와 너비 피처(Feature)를 기반으로 **꽃의 품종 예측**하기 위한 것"
      ],
      "metadata": {
        "id": "mb7vUpEwcu4Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **분류** : 대표적인 **지도학습(Supervised Learning)** 방법의 하나\n",
        "- **지도학습** : **명확한 정답이 주어진 데이터**를 먼저 학습\n",
        "한 뒤 미지의 정답을 예측하는 방식  \n",
        "- **학습 데이터 세트** : 학습을 위해 주어진 데이터 세트 \n",
        "- **테스트 데이터 세트** : 머신러닝 모델의 예측 성능을 평가하기 위해 별도로 주어진 데이터 세트"
      ],
      "metadata": {
        "id": "3RBGc3AAdITi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris                      # 붓꽃 데이터 세트를 생성 → load_iris()\n",
        "from sklearn.tree import DecisionTreeClassifier             # ML 알고리즘 : 의사 결정 트리(Decision Tree) 알고리즘 → DecisionTreeClassifier 적용\n",
        "from sklearn.model_selection import train_test_split        # 데이터 세트를 학습 데이터와 테스트 데이터로 분리하는데 사용하는 함수 → train_test_split() 함수"
      ],
      "metadata": {
        "id": "peIYLrjERTQH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 붓꽃 데이터 세트를 로딩 \n",
        "iris = load_iris()\n",
        "\n",
        "# iris.data : Iris 데이터 세트에서 피처(feature)만으로 된 데이터를 numpy로 가짐 \n",
        "iris_data = iris.data                                                               # 피처 : sepal length, petal length, petal width\n",
        "\n",
        "# iris.target : 붓꽃 데이터 세트에서 레이블(결정 값) 데이터를 numpy로 가짐\n",
        "iris_label = iris.target                                                            # 레이블(Label, 결정값) : 0(Setosa 품종), 1(versicolor 품종), 2(virginica 품종)\n",
        "\n",
        "print('iris target값:', iris_label)\n",
        "print('iris target명:', iris.target_names)\n",
        "\n",
        "# 붓꽃 데이터 세트를 자세히 보기 위해 DataFrame으로 변환\n",
        "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "iris_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "nPAfORRJTQhQ",
        "outputId": "6cb89da1-6253-4262-b324-070b9b1bd62f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iris target값: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "iris target명: ['setosa' 'versicolor' 'virginica']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                5.1               3.5                1.4               0.2   \n",
              "1                4.9               3.0                1.4               0.2   \n",
              "2                4.7               3.2                1.3               0.2   \n",
              "\n",
              "   label  \n",
              "0      0  \n",
              "1      0  \n",
              "2      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7185b0f4-bc7e-4e2e-baf2-353aef75a182\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7185b0f4-bc7e-4e2e-baf2-353aef75a182')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7185b0f4-bc7e-4e2e-baf2-353aef75a182 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7185b0f4-bc7e-4e2e-baf2-353aef75a182');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **학습용 데이터와 테스트용 데이터를 분리**  \n",
        "→ 학습 데이터로 학습된 모델이 얼마나 뛰어난 성능을 가지는지 평가하려면 테스트 데이터 세트 필요하기 때문\n",
        "- train_test_split() : 학습 데이터와 테스트 데이터를 test_size 파라미터 입력값의 비율로 분할"
      ],
      "metadata": {
        "id": "5p0XnlzLh1G5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train : 학습용 피처 데이터 세트, X_test : 테스트용 피처 데이터 세트, y_train : 학습용 레이블 데이터 세트, y_test : 테스트용 레이블 데이터 세트\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label,                      # iris_data : 피처 데이터 세트, iris_label : 레이블 데이터 세트\n",
        "                                                    test_size=0.2, random_state=11)             # test_size : 전체 데이터 중 테스트 데이터 세트의 비율 (test_size = 0.2 : 전체 데이터 중 테스트 데이터 20%, 학습 데이터 80%로 데이터 분할)\n",
        "                                                                                                # random_state : 호출할 때마다 같은 학습/테스트 용 데이터 세트를 생성하기 위해 주어지는 난수 발생 값 (지정하지 않으면, 수행할 때마다 다른 학습/테스트 용 데이터 생성)"
      ],
      "metadata": {
        "id": "MMNi5puvTS_S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 데이터를 기반으로 의사 결정 트리를 이용해 **학습** 수행"
      ],
      "metadata": {
        "id": "vAkdCnowm79z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DecisionTreeClassifier 객체 생성 \n",
        "dt_clf = DecisionTreeClassifier(random_state=11)        # random_state = 11 : 동일한 학습/예측 결과를 출력하기 위한 용도\n",
        "\n",
        "# 학습 수행 \n",
        "dt_clf.fit(X_train, y_train)                            # 생성된 DecisionTreeClassifier 객체의 fit() 메서드에 학습용 피처 데이터 속성과 결정값 데이터 세트를 입력해 호출하여 학습 수행"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "XSgrQruLTaNE",
        "outputId": "fc83c23e-d8af-472c-d48f-ea34c8a09c84"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(random_state=11)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=11)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=11)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습된 DecisionTreeClassifier 객체를 이용해 **예측** 수행\n",
        "- 예측은 **반드시 학습 데이터가 아닌 다른 데이터 이용**해야 함 "
      ],
      "metadata": {
        "id": "_MIi0evzm2bw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습이 완료된 DecisionTreeClassifier 객체에서 테스트 데이터 세트로 예측 수행. \n",
        "pred = dt_clf.predict(X_test)           # DecisionTreeClassifier 객체의 predict() 메서드에 테스트용 피처 데이터 세트를 입력해 호출하면, 학습된 모델 기반에서 테스트 데이터 세트에 대한 예측값을 반환"
      ],
      "metadata": {
        "id": "r50yCTJ1Tbol"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 예측 결과를 기반으로 의사 결정 트리 기반의 DecisionTreeClassifier의 예측 성능 평가 = **정확도** 측정\n",
        "- **정확도** : 예측 결과가 실제 레이블 값과 얼마나 정확하게 맞는지를 평가하는 지표 → accuracy_score() 함수 사용"
      ],
      "metadata": {
        "id": "UVA5Tpr0nqid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score      \n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))             # accuracy_score()의 첫 번째 파라미터 : 실제 레이블 데이터 세트, 두 번째 파라미터 : 예측 레이블 데이터 세트"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x-UPydTTcjl",
        "outputId": "58fa6d51-e0ce-4360-bf46-9e38ab6ca46d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도: 0.9333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 사이킷런의 기반 프레임워크 익히기"
      ],
      "metadata": {
        "id": "nrEmxubTRJty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estimator 이해 및 fit(), predict() 메서드"
      ],
      "metadata": {
        "id": "WDb9HZ3HRZpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "print(type(iris_data))"
      ],
      "metadata": {
        "id": "M4mfXJynRW0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys = iris_data.keys()\n",
        "print('붓꽃 데이터 세트의 키들:', keys)"
      ],
      "metadata": {
        "id": "ScM15hsoTiVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n feature_names 의 type:',type(iris_data.feature_names))\n",
        "print(' feature_names 의 shape:',len(iris_data.feature_names))\n",
        "print(iris_data.feature_names)\n",
        "\n",
        "print('\\n target_names 의 type:',type(iris_data.target_names))\n",
        "print(' feature_names 의 shape:',len(iris_data.target_names))\n",
        "print(iris_data.target_names)\n",
        "\n",
        "print('\\n data 의 type:',type(iris_data.data))\n",
        "print(' data 의 shape:',iris_data.data.shape)\n",
        "print(iris_data['data'])\n",
        "\n",
        "print('\\n target 의 type:',type(iris_data.target))\n",
        "print(' target 의 shape:',iris_data.target.shape)\n",
        "print(iris_data.target)"
      ],
      "metadata": {
        "id": "0Ga_44gHTmAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 사이킷런의 주요 모듈"
      ],
      "metadata": {
        "id": "jes7kf6SRh6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "R23w2OnGRpTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 내장된 예제 데이터 세트"
      ],
      "metadata": {
        "id": "tNr4AO19RpsP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o3hyiTpkRlyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Model Selection 모듈 소개"
      ],
      "metadata": {
        "id": "Yr6TD2p2RXRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습/테스트 데이터 세트 분리 - train_test_split()"
      ],
      "metadata": {
        "id": "4zVFZieCR1Dc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "train_data = iris.data\n",
        "train_label = iris.target\n",
        "dt_clf.fit(train_data, train_label)\n",
        "\n",
        "# 학습 데이터 셋으로 예측 수행\n",
        "pred = dt_clf.predict(train_data)\n",
        "print('예측 정확도:',accuracy_score(train_label,pred))"
      ],
      "metadata": {
        "id": "nHOCghq3Rz7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dt_clf = DecisionTreeClassifier( )\n",
        "iris_data = load_iris()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, \n",
        "                                                    test_size=0.3, random_state=121)"
      ],
      "metadata": {
        "id": "2ShMXPF_TtvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf.fit(X_train, y_train)\n",
        "pred = dt_clf.predict(X_test)\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
      ],
      "metadata": {
        "id": "82sTEznUTu4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 교차 검증"
      ],
      "metadata": {
        "id": "m1uiEi-_R8F3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K 폴드"
      ],
      "metadata": {
        "id": "l6gixJBpTv79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성.\n",
        "kfold = KFold(n_splits=5)\n",
        "cv_accuracy = []\n",
        "print('붓꽃 데이터 세트 크기:',features.shape[0])"
      ],
      "metadata": {
        "id": "0xNwAsRrR_bF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_iter = 0\n",
        "\n",
        "# KFold객체의 split( ) 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환  \n",
        "for train_index, test_index  in kfold.split(features):\n",
        "    # kfold.split( )으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "    #학습 및 예측 \n",
        "    dt_clf.fit(X_train , y_train)    \n",
        "    pred = dt_clf.predict(X_test)\n",
        "    n_iter += 1\n",
        "    # 반복 시 마다 정확도 측정 \n",
        "    accuracy = np.round(accuracy_score(y_test,pred), 4)\n",
        "    train_size = X_train.shape[0]\n",
        "    test_size = X_test.shape[0]\n",
        "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
        "          .format(n_iter, accuracy, train_size, test_size))\n",
        "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
        "    cv_accuracy.append(accuracy)\n",
        "    \n",
        "# 개별 iteration별 정확도를 합하여 평균 정확도 계산 \n",
        "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy)) "
      ],
      "metadata": {
        "id": "I9X3sifgT2Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stratified K 폴드"
      ],
      "metadata": {
        "id": "f6Nh5oOCT3GP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "iris_df['label']=iris.target\n",
        "iris_df['label'].value_counts()"
      ],
      "metadata": {
        "id": "JuFqRgKOT9PJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3)\n",
        "# kfold.split(X)는 폴드 세트를 3번 반복할 때마다 달라지는 학습/테스트 용 데이터 로우 인덱스 번호 반환. \n",
        "n_iter =0\n",
        "for train_index, test_index  in kfold.split(iris_df):\n",
        "    n_iter += 1\n",
        "    label_train= iris_df['label'].iloc[train_index]\n",
        "    label_test= iris_df['label'].iloc[test_index]\n",
        "    print('## 교차 검증: {0}'.format(n_iter))\n",
        "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
      ],
      "metadata": {
        "id": "9uqoLMpFT_Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "n_iter=0\n",
        "\n",
        "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
        "    n_iter += 1\n",
        "    label_train= iris_df['label'].iloc[train_index]\n",
        "    label_test= iris_df['label'].iloc[test_index]\n",
        "    print('## 교차 검증: {0}'.format(n_iter))\n",
        "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
      ],
      "metadata": {
        "id": "k-8DOjyUUA_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=3)\n",
        "n_iter=0\n",
        "cv_accuracy=[]\n",
        "\n",
        "# StratifiedKFold의 split( ) 호출시 반드시 레이블 데이터 셋도 추가 입력 필요  \n",
        "for train_index, test_index  in skfold.split(features, label):\n",
        "    # split( )으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "    #학습 및 예측 \n",
        "    dt_clf.fit(X_train , y_train)    \n",
        "    pred = dt_clf.predict(X_test)\n",
        "\n",
        "    # 반복 시 마다 정확도 측정 \n",
        "    n_iter += 1\n",
        "    accuracy = np.round(accuracy_score(y_test,pred), 4)\n",
        "    train_size = X_train.shape[0]\n",
        "    test_size = X_test.shape[0]\n",
        "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
        "          .format(n_iter, accuracy, train_size, test_size))\n",
        "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
        "    cv_accuracy.append(accuracy)\n",
        "    \n",
        "# 교차 검증별 정확도 및 평균 정확도 계산 \n",
        "print('\\n## 교차 검증별 정확도:', np.round(cv_accuracy, 4))\n",
        "print('## 평균 검증 정확도:', np.round(np.mean(cv_accuracy), 4))"
      ],
      "metadata": {
        "id": "xZopEwa6UCo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cross_val_score()"
      ],
      "metadata": {
        "id": "UgW6s17JUGHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score , cross_validate\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "data = iris_data.data\n",
        "label = iris_data.target\n",
        "\n",
        "# 성능 지표는 정확도(accuracy) , 교차 검증 세트는 3개 \n",
        "scores = cross_val_score(dt_clf , data , label , scoring='accuracy',cv=3)\n",
        "print('교차 검증별 정확도:',np.round(scores, 4))\n",
        "print('평균 검증 정확도:', np.round(np.mean(scores), 4))"
      ],
      "metadata": {
        "id": "tVcpHyg3UM9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에"
      ],
      "metadata": {
        "id": "yCrysDVLSFDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 데이터를 로딩하고 학습데이타와 테스트 데이터 분리\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, \n",
        "                                                    test_size=0.2, random_state=121)\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "### parameter 들을 dictionary 형태로 설정\n",
        "parameters = {'max_depth':[1,2,3], 'min_samples_split':[2,3]}"
      ],
      "metadata": {
        "id": "BKQ8q42iSMtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# param_grid의 하이퍼 파라미터들을 3개의 train, test set fold 로 나누어서 테스트 수행 설정.  \n",
        "### refit=True 가 default 임. True이면 가장 좋은 파라미터 설정으로 재 학습 시킴.  \n",
        "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
        "\n",
        "# 붓꽃 Train 데이터로 param_grid의 하이퍼 파라미터들을 순차적으로 학습/평가 .\n",
        "grid_dtree.fit(X_train, y_train)\n",
        "\n",
        "# GridSearchCV 결과 추출하여 DataFrame으로 변환\n",
        "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score', \\\n",
        "           'split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ],
      "metadata": {
        "id": "4bTMTDiHUZk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
        "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dtree.best_score_))"
      ],
      "metadata": {
        "id": "u6qVl5DfUbmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GridSearchCV의 refit으로 이미 학습이 된 estimator 반환\n",
        "estimator = grid_dtree.best_estimator_\n",
        "\n",
        "# GridSearchCV의 best_estimator_는 이미 최적 하이퍼 파라미터로 학습이 됨\n",
        "pred = estimator.predict(X_test)\n",
        "print('테스트 데이터 세트 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
      ],
      "metadata": {
        "id": "mfQNpAlKUclX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 데이터 전처리"
      ],
      "metadata": {
        "id": "2dYBnUdtSOsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 인코딩"
      ],
      "metadata": {
        "id": "DH_zWE36SRMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 레이블 인코딩 (Label encoding)"
      ],
      "metadata": {
        "id": "bMnZqzmeUhJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "items=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
        "\n",
        "# LabelEncoder를 객체로 생성한 후 , fit( ) 과 transform( ) 으로 label 인코딩 수행. \n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels = encoder.transform(items)\n",
        "print('인코딩 변환값:',labels)"
      ],
      "metadata": {
        "id": "ysMdccOWSQSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('인코딩 클래스:',encoder.classes_)"
      ],
      "metadata": {
        "id": "auXW3QCEUqBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('디코딩 원본 값:',encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3]))"
      ],
      "metadata": {
        "id": "OvBZHOLVUrUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 원-핫 인코딩(One-Hot encoding)"
      ],
      "metadata": {
        "id": "j9WNU4E-UtkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "items=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
        "\n",
        "# 2차원 ndarray로 변환합니다. \n",
        "items = np.array(items).reshape(-1, 1)\n",
        "\n",
        "# 원-핫 인코딩을 적용합니다. \n",
        "oh_encoder = OneHotEncoder()\n",
        "oh_encoder.fit(items)\n",
        "oh_labels = oh_encoder.transform(items)\n",
        "\n",
        "# OneHotEncoder로 변환한 결과는 희소행렬이므로 toarray()를 이용해 밀집 행렬로 변환. \n",
        "print('원-핫 인코딩 데이터')\n",
        "print(oh_labels.toarray())\n",
        "print('원-핫 인코딩 데이터 차원')\n",
        "print(oh_labels.shape)"
      ],
      "metadata": {
        "id": "yvaEcKedUuwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'item':['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서'] })\n",
        "pd.get_dummies(df)"
      ],
      "metadata": {
        "id": "bi_QhP6_UwWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 피처 스케일링과 정규화"
      ],
      "metadata": {
        "id": "UNz5tSJmSVZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## StandardScaler"
      ],
      "metadata": {
        "id": "A_6Sb6vuSZhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "# 붓꽃 데이터 셋을 로딩하고 DataFrame으로 변환합니다. \n",
        "iris = load_iris()\n",
        "iris_data = iris.data\n",
        "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
        "\n",
        "print('feature 들의 평균 값')\n",
        "print(iris_df.mean())\n",
        "print('\\nfeature 들의 분산 값')\n",
        "print(iris_df.var())"
      ],
      "metadata": {
        "id": "3PMO74BESXfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# StandardScaler객체 생성\n",
        "scaler = StandardScaler()\n",
        "# StandardScaler 로 데이터 셋 변환. fit( ) 과 transform( ) 호출.  \n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)\n",
        "\n",
        "#transform( )시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
        "print('feature 들의 평균 값')\n",
        "print(iris_df_scaled.mean())\n",
        "print('\\nfeature 들의 분산 값')\n",
        "print(iris_df_scaled.var())"
      ],
      "metadata": {
        "id": "OID0NLUbSc4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MinMaxScaler"
      ],
      "metadata": {
        "id": "b1xPF5JqSee0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# MinMaxScaler객체 생성\n",
        "scaler = MinMaxScaler()\n",
        "# MinMaxScaler 로 데이터 셋 변환. fit() 과 transform() 호출.  \n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)\n",
        "\n",
        "# transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
        "print('feature들의 최솟값')\n",
        "print(iris_df_scaled.min())\n",
        "print('\\nfeature들의 최댓값')\n",
        "print(iris_df_scaled.max())"
      ],
      "metadata": {
        "id": "B0_ngjF5Sgq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습 데이터와 테스트 데이터의 스케일링 변환 시 유의점"
      ],
      "metadata": {
        "id": "N8a17BZiSiDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# 학습 데이터는 0 부터 10까지, 테스트 데이터는 0 부터 5까지 값을 가지는 데이터 세트로 생성\n",
        "# Scaler클래스의 fit(), transform()은 2차원 이상 데이터만 가능하므로 reshape(-1, 1)로 차원 변경\n",
        "train_array = np.arange(0, 11).reshape(-1, 1)\n",
        "test_array =  np.arange(0, 6).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "yQ4gDal_Sms4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MinMaxScaler 객체에 별도의 feature_range 파라미터 값을 지정하지 않으면 0~1 값으로 변환\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# fit()하게 되면 train_array 데이터의 최솟값이 0, 최댓값이 10으로 설정.\n",
        "scaler.fit(train_array)\n",
        "\n",
        "# 1/10 scale로 train_array 데이터 변환함. 원본 10-> 1로 변환됨.\n",
        "train_scaled = scaler.transform(train_array)\n",
        "\n",
        "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
        "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))"
      ],
      "metadata": {
        "id": "x5NBHNuFVJxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MinMaxScaler에 test_array를 fit()하게 되면 원본 데이터의 최솟값이 0, 최댓값이 5로 설정됨\n",
        "scaler.fit(test_array)\n",
        "\n",
        "# 1/5 scale로 test_array 데이터 변환함. 원본 5->1로 변환.\n",
        "test_scaled = scaler.transform(test_array)\n",
        "\n",
        "# test_array의 scale 변환 출력.\n",
        "print('원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
        "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))"
      ],
      "metadata": {
        "id": "5bCfY9qmVNgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(train_array)\n",
        "train_scaled = scaler.transform(train_array)\n",
        "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
        "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))\n",
        "\n",
        "# test_array에 Scale 변환을 할 때는 반드시 fit()을 호출하지 않고 transform() 만으로 변환해야 함. \n",
        "test_scaled = scaler.transform(test_array)\n",
        "print('\\n원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
        "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))"
      ],
      "metadata": {
        "id": "oSvItryKVPCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. 사이킷런으로 수행하는 타이타닉 생존자 예측"
      ],
      "metadata": {
        "id": "Br7DtrGsSoX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "titanic_df = pd.read_csv('./titanic_train.csv')\n",
        "titanic_df.head(3)"
      ],
      "metadata": {
        "id": "R2SIO_sNSrmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n ### train 데이터 정보 ###  \\n')\n",
        "print(titanic_df.info())"
      ],
      "metadata": {
        "id": "rddgsxN8VSuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df['Age'].fillna(titanic_df['Age'].mean(),inplace=True)\n",
        "titanic_df['Cabin'].fillna('N',inplace=True)\n",
        "titanic_df['Embarked'].fillna('N',inplace=True)\n",
        "print('데이터 세트 Null 값 갯수 ',titanic_df.isnull().sum().sum())"
      ],
      "metadata": {
        "id": "yoBreGi3VUDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(' Sex 값 분포 :\\n',titanic_df['Sex'].value_counts())\n",
        "print('\\n Cabin 값 분포 :\\n',titanic_df['Cabin'].value_counts())\n",
        "print('\\n Embarked 값 분포 :\\n',titanic_df['Embarked'].value_counts())"
      ],
      "metadata": {
        "id": "KYvugBkjVV4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df['Cabin'] = titanic_df['Cabin'].str[:1]\n",
        "print(titanic_df['Cabin'].head(3))"
      ],
      "metadata": {
        "id": "_ButNnKyVW6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df.groupby(['Sex','Survived'])['Survived'].count()"
      ],
      "metadata": {
        "id": "9icoGxx5VX1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='Sex', y = 'Survived', data=titanic_df)"
      ],
      "metadata": {
        "id": "MmJSk8HYVhpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='Pclass', y='Survived', hue='Sex', data=titanic_df)"
      ],
      "metadata": {
        "id": "2jAaEu9zViJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 age에 따라 구분값을 반환하는 함수 설정. DataFrame의 apply lambda식에 사용. \n",
        "def get_category(age):\n",
        "    cat = ''\n",
        "    if age <= -1: cat = 'Unknown'\n",
        "    elif age <= 5: cat = 'Baby'\n",
        "    elif age <= 12: cat = 'Child'\n",
        "    elif age <= 18: cat = 'Teenager'\n",
        "    elif age <= 25: cat = 'Student'\n",
        "    elif age <= 35: cat = 'Young Adult'\n",
        "    elif age <= 60: cat = 'Adult'\n",
        "    else : cat = 'Elderly'\n",
        "    \n",
        "    return cat\n",
        "\n",
        "# 막대그래프의 크기 figure를 더 크게 설정 \n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "#X축의 값을 순차적으로 표시하기 위한 설정 \n",
        "group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Elderly']\n",
        "\n",
        "# lambda 식에 위에서 생성한 get_category( ) 함수를 반환값으로 지정. \n",
        "# get_category(X)는 입력값으로 'Age' 컬럼값을 받아서 해당하는 cat 반환\n",
        "titanic_df['Age_cat'] = titanic_df['Age'].apply(lambda x : get_category(x))\n",
        "sns.barplot(x='Age_cat', y = 'Survived', hue='Sex', data=titanic_df, order=group_names)\n",
        "titanic_df.drop('Age_cat', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "I0wHDqAUVjW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "def encode_features(dataDF):\n",
        "    features = ['Cabin', 'Sex', 'Embarked']\n",
        "    for feature in features:\n",
        "        le = preprocessing.LabelEncoder()\n",
        "        le = le.fit(dataDF[feature])\n",
        "        dataDF[feature] = le.transform(dataDF[feature])\n",
        "        \n",
        "    return dataDF\n",
        "\n",
        "titanic_df = encode_features(titanic_df)\n",
        "titanic_df.head()"
      ],
      "metadata": {
        "id": "Kz8TIH_LVlFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Null 처리 함수\n",
        "def fillna(df):\n",
        "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "    df['Cabin'].fillna('N', inplace=True)\n",
        "    df['Embarked'].fillna('N', inplace=True)\n",
        "    df['Fare'].fillna(0, inplace=True)\n",
        "    return df\n",
        "\n",
        "# 머신러닝 알고리즘에 불필요한 피처 제거\n",
        "def drop_features(df):\n",
        "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "# 레이블 인코딩 수행.\n",
        "def format_features(df):\n",
        "    df['Cabin'] = df['Cabin'].str[:1]\n",
        "    features = ['Cabin', 'Sex', 'Embarked']\n",
        "    for feature in features:\n",
        "        le = LabelEncoder()\n",
        "        le = le.fit(df[feature])\n",
        "        df[feature] = le.transform(df[feature])\n",
        "    return df\n",
        "\n",
        "# 앞에서 설정한 데이터 전처리 함수 호출\n",
        "def transform_features(df):\n",
        "    df = fillna(df)\n",
        "    df = drop_features(df)\n",
        "    df = format_features(df)\n",
        "    return df"
      ],
      "metadata": {
        "id": "TAtBf6oUVmck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 데이터를 재로딩 하고, feature데이터 셋과 Label 데이터 셋 추출. \n",
        "titanic_df = pd.read_csv('./titanic_train.csv')\n",
        "y_titanic_df = titanic_df['Survived']\n",
        "X_titanic_df= titanic_df.drop('Survived',axis=1)\n",
        "\n",
        "X_titanic_df = transform_features(X_titanic_df)"
      ],
      "metadata": {
        "id": "yISeEBfiVqPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, \\\n",
        "                                                  test_size=0.2, random_state=11)"
      ],
      "metadata": {
        "id": "Ms7HUBD1VrYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 결정트리, Random Forest, 로지스틱 회귀를 위한 사이킷런 Classifier 클래스 생성\n",
        "dt_clf = DecisionTreeClassifier(random_state=11)\n",
        "rf_clf = RandomForestClassifier(random_state=11)\n",
        "lr_clf = LogisticRegression(solver='liblinear')\n",
        "\n",
        "# DecisionTreeClassifier 학습/예측/평가\n",
        "dt_clf.fit(X_train , y_train)\n",
        "dt_pred = dt_clf.predict(X_test)\n",
        "print('DecisionTreeClassifier 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
        "\n",
        "# RandomForestClassifier 학습/예측/평가\n",
        "rf_clf.fit(X_train , y_train)\n",
        "rf_pred = rf_clf.predict(X_test)\n",
        "print('RandomForestClassifier 정확도:{0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
        "\n",
        "# LogisticRegression 학습/예측/평가\n",
        "lr_clf.fit(X_train , y_train)\n",
        "lr_pred = lr_clf.predict(X_test)\n",
        "print('LogisticRegression 정확도: {0:.4f}'.format(accuracy_score(y_test, lr_pred)))"
      ],
      "metadata": {
        "id": "YjjPFvgdVsi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def exec_kfold(clf, folds=5):\n",
        "    # 폴드 세트를 5개인 KFold객체를 생성, 폴드 수만큼 예측결과 저장을 위한  리스트 객체 생성.\n",
        "    kfold = KFold(n_splits=folds)\n",
        "    scores = []\n",
        "    \n",
        "    # KFold 교차 검증 수행. \n",
        "    for iter_count , (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
        "        # X_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성\n",
        "        X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n",
        "        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
        "        \n",
        "        # Classifier 학습, 예측, 정확도 계산 \n",
        "        clf.fit(X_train, y_train) \n",
        "        predictions = clf.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, predictions)\n",
        "        scores.append(accuracy)\n",
        "        print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))     \n",
        "    \n",
        "    # 5개 fold에서의 평균 정확도 계산. \n",
        "    mean_score = np.mean(scores)\n",
        "    print(\"평균 정확도: {0:.4f}\".format(mean_score)) \n",
        "# exec_kfold 호출\n",
        "exec_kfold(dt_clf , folds=5) "
      ],
      "metadata": {
        "id": "sc-o1Ze_VuFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {'max_depth':[2,3,5,10],\n",
        "             'min_samples_split':[2,3,5], 'min_samples_leaf':[1,5,8]}\n",
        "\n",
        "grid_dclf = GridSearchCV(dt_clf , param_grid=parameters , scoring='accuracy' , cv=5)\n",
        "grid_dclf.fit(X_train , y_train)\n",
        "\n",
        "print('GridSearchCV 최적 하이퍼 파라미터 :',grid_dclf.best_params_)\n",
        "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dclf.best_score_))\n",
        "best_dclf = grid_dclf.best_estimator_\n",
        "\n",
        "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행. \n",
        "dpredictions = best_dclf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test , dpredictions)\n",
        "print('테스트 세트에서의 DecisionTreeClassifier 정확도 : {0:.4f}'.format(accuracy))"
      ],
      "metadata": {
        "id": "QNcA2VyLV2bq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}